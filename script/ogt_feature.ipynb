{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83d806c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import optuna\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a8059e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1019743/1205574855.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  X_embeddings = torch.load(embedding_file)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 加载嵌入\n",
    "embedding_file = '/mnt/data/lzp/OGT/output/protein_embeddings.pt'\n",
    "X_embeddings = torch.load(embedding_file)\n",
    "\n",
    "# 将嵌入数据转换为 NumPy 数组\n",
    "if isinstance(X_embeddings, list):\n",
    "    X_embeddings = [torch.tensor(embed) for embed in X_embeddings]\n",
    "    X = torch.cat(X_embeddings, dim=0).numpy()\n",
    "else:\n",
    "    X = X_embeddings.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74351c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_698839/3050903343.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  X_embeddings = torch.load(embedding_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_combined shape: (93220, 4373)\n",
      "第1行第4373列的值是: 99.23076923076924\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import optuna\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ==== 设置设备 ====\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ==== 加载数据 ====\n",
    "embedding_file = '/mnt/data/lzp/OGT/output/protein_embeddings.pt'\n",
    "X_embeddings = torch.load(embedding_file)\n",
    "\n",
    "if isinstance(X_embeddings, list):\n",
    "    X_embeddings = [torch.tensor(embed) for embed in X_embeddings]\n",
    "    X = torch.cat(X_embeddings, dim=0).numpy()\n",
    "else:\n",
    "    X = X_embeddings.numpy()\n",
    "    \n",
    "# 加载物理化学特征并忽略第一行作为列名\n",
    "protein_features_file = '/mnt/data/lzp/OGT/result/ifeature_result/protein_features.csv'\n",
    "protein_features = pd.read_csv(protein_features_file, header=1)  # 从第二行开始读取数据\n",
    "# 删除第一列\n",
    "protein_features = protein_features.drop(protein_features.columns[0], axis=1)\n",
    "protein_features = protein_features.iloc[:X.shape[0], :]  # 保留前 93220 行\n",
    "X_combined = np.concatenate([X, protein_features.values], axis=1)\n",
    "print(\"X_combined shape:\", X_combined.shape)\n",
    "print(\"第1行第4373列的值是:\", X_combined[0, 4372])\n",
    "\n",
    "\n",
    "labels_file = '/mnt/data/lzp/OGT/output/protein_labels.csv'\n",
    "y = pd.read_csv(labels_file)['ogt'].values\n",
    "\n",
    "# ==== 划分数据 ====\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd971fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93220, 1280)\n",
      "(93220,)\n",
      "(74576, 4373)\n",
      "(18644, 4373)\n",
      "(74576,)\n",
      "(18644,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1bb9bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.13919732 -0.02285788  0.05318638 ... -0.22690704  0.10845955\n",
      "  -0.05633758]\n",
      " [ 0.11506157 -0.02977298  0.05750177 ... -0.23991719  0.11758859\n",
      "  -0.07531863]]\n"
     ]
    }
   ],
   "source": [
    "print(X[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8da08521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   protein_1  0.0899280575539568  0.0071942446043165  0.0539568345323741  \\\n",
      "0  protein_2            0.103846            0.011538            0.046154   \n",
      "1  protein_3            0.077586            0.014368            0.040230   \n",
      "\n",
      "   0.1151079136690647  0.0287769784172661  0.079136690647482  \\\n",
      "0            0.084615            0.023077           0.088462   \n",
      "1            0.077586            0.034483           0.103448   \n",
      "\n",
      "   0.0179856115107913  0.0683453237410072  0.079136690647482.1  ...  \\\n",
      "0            0.015385            0.084615             0.065385  ...   \n",
      "1            0.017241            0.068966             0.071839  ...   \n",
      "\n",
      "   0.7194244604316548.7  25.179856115107917.3  51.43884892086332.1  \\\n",
      "0              1.923077             21.153846            42.307692   \n",
      "1              0.862069             24.137931            48.563218   \n",
      "\n",
      "   76.97841726618705.3  99.28057553956836.11  0.3597122302158274.12  \\\n",
      "0            75.384615                 100.0               0.384615   \n",
      "1            73.275862                 100.0               0.287356   \n",
      "\n",
      "   22.66187050359712  47.84172661870504.1  69.7841726618705  98.20143884892086  \n",
      "0          37.307692            59.230769         76.153846          99.230769  \n",
      "1          18.678161            43.965517         74.425287          99.425287  \n",
      "\n",
      "[2 rows x 3094 columns]\n"
     ]
    }
   ],
   "source": [
    "# 加载物理化学特征并忽略第一行作为列名\n",
    "protein_features_file = '/mnt/data/lzp/OGT/result/ifeature_result/protein_features.csv'\n",
    "protein_features = pd.read_csv(protein_features_file, header=1)  # 从第二行开始读取数据\n",
    "\n",
    "print(protein_features.head(2))  # 查看前两行数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "838ac266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0.0899280575539568  0.0071942446043165  0.0539568345323741  \\\n",
      "0            0.103846            0.011538            0.046154   \n",
      "1            0.077586            0.014368            0.040230   \n",
      "\n",
      "   0.1151079136690647  0.0287769784172661  0.079136690647482  \\\n",
      "0            0.084615            0.023077           0.088462   \n",
      "1            0.077586            0.034483           0.103448   \n",
      "\n",
      "   0.0179856115107913  0.0683453237410072  0.079136690647482.1  \\\n",
      "0            0.015385            0.084615             0.065385   \n",
      "1            0.017241            0.068966             0.071839   \n",
      "\n",
      "   0.0863309352517985  ...  0.7194244604316548.7  25.179856115107917.3  \\\n",
      "0            0.073077  ...              1.923077             21.153846   \n",
      "1            0.074713  ...              0.862069             24.137931   \n",
      "\n",
      "   51.43884892086332.1  76.97841726618705.3  99.28057553956836.11  \\\n",
      "0            42.307692            75.384615                 100.0   \n",
      "1            48.563218            73.275862                 100.0   \n",
      "\n",
      "   0.3597122302158274.12  22.66187050359712  47.84172661870504.1  \\\n",
      "0               0.384615          37.307692            59.230769   \n",
      "1               0.287356          18.678161            43.965517   \n",
      "\n",
      "   69.7841726618705  98.20143884892086  \n",
      "0         76.153846          99.230769  \n",
      "1         74.425287          99.425287  \n",
      "\n",
      "[2 rows x 3093 columns]\n"
     ]
    }
   ],
   "source": [
    "# 删除第一列\n",
    "protein_features = protein_features.drop(protein_features.columns[0], axis=1)\n",
    "print(protein_features.head(2))  # 查看前两行数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7deee03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93320, 3093)\n"
     ]
    }
   ],
   "source": [
    "print(protein_features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c54ac70",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_features = protein_features.iloc[:X.shape[0], :]  # 保留前 93220 行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a3e77cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_combined = np.concatenate([X, protein_features.values], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f5eb78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_combined shape: (93220, 4373)\n",
      "第1行第4373列的值是: 99.23076923076924\n"
     ]
    }
   ],
   "source": [
    "print(\"X_combined shape:\", X_combined.shape)\n",
    "print(\"第1行第4373列的值是:\", X_combined[0, 4372])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "869aa545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载标签\n",
    "labels_file = '/mnt/data/lzp/OGT/output/protein_labels.csv'\n",
    "y = pd.read_csv(labels_file)['ogt'].values\n",
    "\n",
    "# 数据分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0501642b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 定义一个更深的深度神经网络 (DNN) 模型\n",
    "class DNNModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(DNNModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 512)\n",
    "        self.bn1 = nn.BatchNorm1d(512)  # 添加 Batch Normalization\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.fc4 = nn.Linear(128, 1)  # 输出为一个标量，回归任务\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.3)  # 增加 Dropout 比例\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.fc1(x)))  # 加入 Batch Normalization\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.bn2(self.fc2(x)))  # 加入 Batch Normalization\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.bn3(self.fc3(x)))  # 加入 Batch Normalization\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "# 将训练数据转为 PyTorch 张量\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)  # 回归任务，输出为一维\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# 创建 DataLoader\n",
    "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_data = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)  # 调整批量大小\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
    "\n",
    "# 初始化模型\n",
    "input_dim = X_train.shape[1]  # 特征维度\n",
    "model = DNNModel(input_dim)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.MSELoss()  # 均方误差损失函数\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.01)  # 加入 L2 正则化\n",
    "\n",
    "# 训练模型\n",
    "epochs = 300  # 增加训练轮数\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# 测试模型\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_tensor = model(X_test_tensor)\n",
    "\n",
    "# 将预测结果转换为 numpy 数组\n",
    "y_pred = y_pred_tensor.numpy()\n",
    "\n",
    "# 计算评价指标\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# 输出评价指标\n",
    "print(\"\\n深度学习回归模型评价指标：\")\n",
    "print(f\"均方误差 (MSE): {mse:.2f}\")\n",
    "print(f\"决定系数 (R²): {r2:.2f}\")\n",
    "\n",
    "# 可视化实际值与预测值的对比\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.6, color='blue', label='预测值')\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'r--', label='理想预测')\n",
    "plt.xlabel(\"实际值\")\n",
    "plt.ylabel(\"预测值\")\n",
    "plt.title(\"深度学习回归模型：实际值 vs 预测值\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
